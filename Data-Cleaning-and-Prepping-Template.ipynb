{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5072ad7-d902-45ef-9b95-52ddf7c9ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef8800e-c9a7-4114-b0cd-f4b18469a611",
   "metadata": {},
   "source": [
    "# Universal Data Cleaning & Preparation Template\n",
    "\n",
    "This Jupyter Notebook provides a step-by-step template for cleaning and preparing any tabular dataset for machine learning. Follow the cells in order to handle missing values, convert data types, and encode categorical features for optimal model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9ab9ce-f9d4-4566-94cb-9d2539602b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20473332-8d92-4832-b5fd-15fad10cd9bc",
   "metadata": {},
   "source": [
    "### Step 1: Load Your Data\n",
    "\n",
    "In the cell below, replace `'your_dataset.csv'` with the path to your own data file. Make sure the data file is in the same folder as this notebook for the easiest setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f2cc5-57cb-42e8-9715-a930e68d4146",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4961f12-e77c-47f6-99f9-7fd30ceee94d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration: Please set your file path here ---\n",
    "file_path = 'train.csv'\n",
    "\n",
    "# --- Data Loading ---\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "    # Display the first 5 rows to confirm\n",
    "    print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file '{file_path}' was not found.\")\n",
    "    print(\"Please make sure your data file is in the same directory as this notebook and the file_path variable is set correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf27ef2-563c-4656-b52b-9c6379c6351e",
   "metadata": {},
   "source": [
    "### Step 2: Fix Incorrect Data Types\n",
    "\n",
    "This step addresses a common issue where a numeric column is incorrectly read as text (`object`). The code below will convert a specified column to a numeric format. Any values that cannot be converted will be marked as missing data (`NaN`), which we will handle in the next step.\n",
    "\n",
    "**Action Required:** In the code cell below, update the `column_to_fix` variable with the name of the column from your dataset that you need to convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b18bf4e-87af-4d53-bf62-8e118782ab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to convert column: 'TotalCharges'...\n",
      "INFO: Column 'TotalCharges' not found in the DataFrame. Skipping this step.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# The user of this template should change this column name.\n",
    "# We are using 'TotalCharges' because it exists in our current test data.\n",
    "column_to_fix = 'TotalCharges'\n",
    "\n",
    "# --- Execution ---\n",
    "print(f\"Attempting to convert column: '{column_to_fix}'...\")\n",
    "if column_to_fix in df.columns and df[column_to_fix].dtype == 'object':\n",
    "    initial_missing = df[column_to_fix].isnull().sum()\n",
    "    df[column_to_fix] = pd.to_numeric(df[column_to_fix], errors='coerce')\n",
    "    new_missing = df[column_to_fix].isnull().sum()\n",
    "    print(f\"SUCCESS: Column '{column_to_fix}' was converted to a numeric data type.\")\n",
    "    if new_missing > initial_missing:\n",
    "        print(f\"INFO: {new_missing - initial_missing} new missing values (NaN) were created during conversion.\")\n",
    "elif column_to_fix in df.columns:\n",
    "     print(f\"INFO: Column '{column_to_fix}' is already a numeric type. No action needed.\")\n",
    "else:\n",
    "    print(f\"INFO: Column '{column_to_fix}' not found in the DataFrame. Skipping this step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2aa71a-2c05-44bb-a887-8e9df0e20ee2",
   "metadata": {},
   "source": [
    "### Step 3: Handle Missing Values\n",
    "\n",
    "Machine learning models cannot work with missing values (NaN). We need to either drop the rows containing them or fill them with a meaningful value (a process called imputation).\n",
    "\n",
    "The code below will automatically find all numeric columns that have missing values and fill them with the **mean** (average) of that column. This is a common and robust strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ddb3c2-e2a9-4f3d-819d-3e1465a10b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Values Before Filling ---\n",
      "Series([], dtype: int64)\n",
      "\n",
      "--- Missing Values After Filling ---\n",
      "Id               0\n",
      "MSSubClass       0\n",
      "MSZoning         0\n",
      "LotFrontage      0\n",
      "LotArea          0\n",
      "                ..\n",
      "MoSold           0\n",
      "YrSold           0\n",
      "SaleType         0\n",
      "SaleCondition    0\n",
      "SalePrice        0\n",
      "Length: 81, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- This is the new, improved code for the \"Handle Missing Values\" cell ---\n",
    "\n",
    "print(\"--- Missing Values Before Filling ---\")\n",
    "missing_values_before = df.isnull().sum()\n",
    "print(missing_values_before[missing_values_before > 0]) # Show only columns with missing values\n",
    "\n",
    "# Loop through all columns that have missing values\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().any(): # If a column has any nulls\n",
    "        # If the column is numeric, fill with the mean\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            mean_value = df[col].mean()\n",
    "            df[col] = df[col].fillna(mean_value)\n",
    "            print(f\"\\nINFO: Numeric column '{col}' was filled with its mean: {mean_value:.2f}\")\n",
    "        # If the column is text (object), fill with the most frequent value (mode)\n",
    "        elif pd.api.types.is_object_dtype(df[col]):\n",
    "            mode_value = df[col].mode()[0]\n",
    "            df[col] = df[col].fillna(mode_value)\n",
    "            print(f\"\\nINFO: Categorical column '{col}' was filled with its mode: '{mode_value}'\")\n",
    "\n",
    "print(\"\\n--- Missing Values After Filling ---\")\n",
    "# Now, let's verify again. The output should be all zeros.\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c96b7b-b554-4fd5-9c66-f8a19cd3e8b7",
   "metadata": {},
   "source": [
    "### Step 4: Encode Categorical Data\n",
    "\n",
    "Finally, we need to convert all text-based columns into numbers for the model. We will use two techniques:\n",
    "1.  **Binary Encoding:** For columns with only two unique values (e.g., 'Yes'/'No'). These will be mapped to `0` and `1`.\n",
    "2.  **One-Hot Encoding:** For columns with more than two categories. This creates new columns for each category with `0` or `1` values.\n",
    "\n",
    "**Action Required:** In the code cell below, update the `target_column` and `binary_cols_to_map` variables to match your dataset's column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0aaddbe-d6e5-4748-b650-e5f9981fdbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Categorical Encoding ---\n",
      "\n",
      "SUCCESS: The following columns were One-Hot Encoded: ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
      "\n",
      "--- Encoding Complete ---\n",
      "Displaying the first 5 rows of the final, fully numeric DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "3   4          70         60.0     9550            7            5       1915   \n",
       "4   5          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLI  SaleType_ConLw  \\\n",
       "0          2003       196.0         706  ...           False           False   \n",
       "1          1976         0.0         978  ...           False           False   \n",
       "2          2002       162.0         486  ...           False           False   \n",
       "3          1970         0.0         216  ...           False           False   \n",
       "4          2000       350.0         655  ...           False           False   \n",
       "\n",
       "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_AdjLand  \\\n",
       "0         False         False         True                  False   \n",
       "1         False         False         True                  False   \n",
       "2         False         False         True                  False   \n",
       "3         False         False         True                  False   \n",
       "4         False         False         True                  False   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                 False                 False                  True   \n",
       "1                 False                 False                  True   \n",
       "2                 False                 False                  True   \n",
       "3                 False                 False                 False   \n",
       "4                 False                 False                  True   \n",
       "\n",
       "   SaleCondition_Partial  \n",
       "0                  False  \n",
       "1                  False  \n",
       "2                  False  \n",
       "3                  False  \n",
       "4                  False  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# The column you want to predict.\n",
    "target_column = 'Churn' \n",
    "\n",
    "# List of columns that have only two text values (e.g., 'Yes'/'No', 'Male'/'Female').\n",
    "binary_cols_to_map = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
    "\n",
    "# --- Execution ---\n",
    "# Work on a copy to be safe and keep the original df for reference.\n",
    "df_final = df.copy()\n",
    "\n",
    "print(\"--- Starting Categorical Encoding ---\")\n",
    "\n",
    "# Encode other binary columns\n",
    "for col in binary_cols_to_map:\n",
    "    if col in df_final.columns and df_final[col].dtype == 'object':\n",
    "        unique_vals = df_final[col].unique()\n",
    "        if len(unique_vals) == 2:\n",
    "            mapping = {unique_vals[0]: 0, unique_vals[1]: 1}\n",
    "            df_final[col] = df_final[col].map(mapping)\n",
    "            print(f\"SUCCESS: Binary column '{col}' was encoded using mapping: {mapping}\")\n",
    "\n",
    "# Encode the target column (handle it separately for clarity)\n",
    "if target_column in df_final.columns and df_final[target_column].dtype == 'object':\n",
    "     unique_vals = df_final[target_column].unique()\n",
    "     if len(unique_vals) == 2:\n",
    "        mapping = {unique_vals[0]: 0, unique_vals[1]: 1}\n",
    "        df_final[target_column] = df_final[target_column].map(mapping)\n",
    "        print(f\"SUCCESS: Target column '{target_column}' was encoded using mapping: {mapping}\")\n",
    "\n",
    "# One-Hot Encode all remaining 'object' type columns\n",
    "# These are columns with more than 2 text categories\n",
    "object_cols_to_encode = df_final.select_dtypes(include=['object']).columns\n",
    "if len(object_cols_to_encode) > 0:\n",
    "    df_final = pd.get_dummies(df_final, columns=object_cols_to_encode, drop_first=True)\n",
    "    print(f\"\\nSUCCESS: The following columns were One-Hot Encoded: {list(object_cols_to_encode)}\")\n",
    "else:\n",
    "    print(\"\\nINFO: No multi-category columns found to One-Hot Encode.\")\n",
    "\n",
    "print(\"\\n--- Encoding Complete ---\")\n",
    "print(\"Displaying the first 5 rows of the final, fully numeric DataFrame:\")\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72bab89-92bc-40a9-bd62-8ef3d927f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a summary of the DataFrame\n",
    "churn_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b387a35-cbb4-44e1-9005-0629da554c15",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9326c9d-46c4-4346-9fa0-6e095eb57e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix 'TotalCharges' column and drop rows with missing values\n",
    "churn_df['TotalCharges'] = pd.to_numeric(churn_df['TotalCharges'], errors='coerce')\n",
    "churn_df.dropna(inplace=True)\n",
    "\n",
    "# Encode binary and target variables\n",
    "churn_df['Churn'] = churn_df['Churn'].map({'No': 0, 'Yes': 1})\n",
    "churn_df['gender'] = churn_df['gender'].map({'Female': 0, 'Male': 1})\n",
    "binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
    "for col in binary_cols:\n",
    "    churn_df[col] = churn_df[col].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# One-Hot Encode multi-category columns and drop customerID\n",
    "multi_cat_cols = churn_df.select_dtypes(include=['object']).columns.drop(['customerID'])\n",
    "churn_df_final = pd.get_dummies(churn_df, columns=multi_cat_cols, drop_first=True)\n",
    "churn_df_final = churn_df_final.drop('customerID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d456f0-827d-4450-9491-2e1b606ffdf1",
   "metadata": {},
   "source": [
    "### Final Data Check\n",
    "As a final preprocessing step, we clean the column names for API compatibility and check the data types to ensure everything is numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3992fa6e-5037-4805-bfe6-ba5f64fa3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "churn_df_final.columns = churn_df_final.columns.str.replace(' ', '_')\n",
    "\n",
    "# Verify that all columns are now numeric\n",
    "print(\"Final Data Types:\")\n",
    "churn_df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc5328-f66a-4fd9-81e2-8c096e1c007b",
   "metadata": {},
   "source": [
    "## 3. Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7f225-62fd-4a2f-84a3-d14eb8f26f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = churn_df_final.drop('Churn', axis=1)\n",
    "y = churn_df_final['Churn']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11c942-331e-4844-bf32-3609a27f240f",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ba629-07fb-4b5f-b6f0-2a40c93dc226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's accuracy\n",
    "accuracy = log_model.score(X_test_scaled, y_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate the confusion matrix\n",
    "y_pred = log_model.predict(X_test_scaled)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecdb559-d54f-41de-8636-54bad8f1f986",
   "metadata": {},
   "source": [
    "## 5. Save Model and Scaler\n",
    "The final trained model and the scaler are saved to disk for use in the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1b8e4-77fb-4d0c-9eca-4ab721949453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and scaler to disk\n",
    "joblib.dump(log_model, 'churn_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print(\"Model and Scaler saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ad8cd-6697-4831-a7ad-b189044857b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
